Fruits Detection using YOLOv5 & Roboflow

This repository contains a custom fruits object detection model built on top of YOLOv5, trained using a Roboflow dataset of 10 fruit classes.
​

Project overview
10 classes: apple, avocado, banana, cherry, kiwi, mango, orange, pineapple, strawberries, watermelon.
​

20,000+ annotated images prepared and exported from Roboflow in YOLOv5 format.
​

Trained YOLOv5s for 100 epochs at 416×416 resolution on GPU.
​

Best model achieves mAP@0.5 of 0.799 and mAP@0.5:0.95 of 0.595 on the test set.
​

Tech stack
YOLOv5 (PyTorch) for object detection.
​

Roboflow for dataset management, annotation, augmentation and YOLOv5 export.
​

Google Colab with Tesla T4 GPU for training and experimentation.
​

Dataset
The dataset is managed in Roboflow under the project fruitsdetection-wggyt and downloaded directly into the YOLOv5 directory using the Roboflow Python SDK.
​
It includes separate train, validation and test splits with diverse lighting, backgrounds and fruit arrangements.
​

Training
Key training configuration:
​

Base model: yolov5s.pt

Image size: 416

Batch size: 32

Epochs: 100

Data config: dataset.location/data.yaml (auto‑generated by Roboflow)
​

Example training command:

bash
python train.py \
  --img 416 \
  --batch 32 \
  --epochs 100 \
  --data dataset.location/data.yaml \
  --weights yolov5s.pt \
  --cache
Results
Final validation metrics for the best checkpoint:
​

mAP@0.5: 0.799

mAP@0.5:0.95: 0.595

Strong per‑class performance on kiwi and pineapple, with high precision and recall across most fruit categories.
​

The best weights are saved at:

text
runs/train/exp/weights/best.pt
Inference speed is around 5–7 ms per 416×416 image on Tesla T4 (excluding pre‑ and post‑processing).
​

Inference
Run inference on a folder of images:

bash
python detect.py \
  --weights runs/train/exp/weights/best.pt \
  --img 416 \
  --conf 0.1 \
  --source path/to/your/images
Predicted images with bounding boxes and labels will be saved under runs/detect/exp.
​

Comparing with base YOLOv5s
The notebook also evaluates the custom fruits model against the original yolov5s.pt on the same test set to highlight the benefit of class‑specific training.
​

Example command for base model:

bash
python detect.py \
  --weights yolov5s.pt \
  --img 416 \
  --conf 0.1 \
  --source dataset.location/test/images
How to use this repo
Clone YOLOv5 into this project and install requirements.

Use the provided notebook or commands to download the Roboflow dataset.

Train the model with the configuration above.

Run inference on your own fruit images and visualize the detections.
​

Future work
Experiment with larger YOLO variants (YOLOv5m/l/x) for higher accuracy.

Try different input resolutions and augmentations.

Convert the trained model to ONNX / TensorRT for deployment.
